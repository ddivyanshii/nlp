{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Python Code for NLP Pipeline (Question 1)"
      ],
      "metadata": {
        "id": "JlnUlEyjNV3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Libraries"
      ],
      "metadata": {
        "id": "FO4bXMPaPSgx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXUWmuGWMZGD"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download required resources"
      ],
      "metadata": {
        "id": "cA_xSTsQPX0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIH09hQdMddI",
        "outputId": "c4d0d9d2-02b3-44ed-92ee-e3a00a58ea5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custome text(Paragraph) for processing"
      ],
      "metadata": {
        "id": "1qeZkhO5Pf0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_paragraph = \"Natural Language Processing is a fascinating field. It helps computers understand, interpret, and generate human language. We are now performing the entire pipeline to transform the text.\"\n",
        "print(\"--- Step 0: Original Text ---\")\n",
        "print(custom_paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QqQDYI5Misn",
        "outputId": "9a94620b-1489-4f99-e69b-3f7a4088be5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 0: Original Text ---\n",
            "Natural Language Processing is a fascinating field. It helps computers understand, interpret, and generate human language. We are now performing the entire pipeline to transform the text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Tokenization"
      ],
      "metadata": {
        "id": "ULIUu72sPrIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(custom_paragraph)\n",
        "print(\"--- Step 1: Tokenization ---\")\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-NnrzfKMnvl",
        "outputId": "b521522e-1251-4080-a7a4-5e4d3737c089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 1: Tokenization ---\n",
            "['Natural', 'Language', 'Processing', 'is', 'a', 'fascinating', 'field', '.', 'It', 'helps', 'computers', 'understand', ',', 'interpret', ',', 'and', 'generate', 'human', 'language', '.', 'We', 'are', 'now', 'performing', 'the', 'entire', 'pipeline', 'to', 'transform', 'the', 'text', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Stopword Removal (and Lowercasing)"
      ],
      "metadata": {
        "id": "YoOLK_PGPxO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word.lower() for word in tokens if word.lower() not in stop_words and word.isalpha()]\n",
        "print(\"--- Step 2: Stopword Removal (and Lowercasing) ---\")\n",
        "print(filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-N9rHv6MuAH",
        "outputId": "24ad5832-ea2a-44a4-8bae-7289d2822c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 2: Stopword Removal (and Lowercasing) ---\n",
            "['natural', 'language', 'processing', 'fascinating', 'field', 'helps', 'computers', 'understand', 'interpret', 'generate', 'human', 'language', 'performing', 'entire', 'pipeline', 'transform', 'text']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Stemming (Porter Stemmer)"
      ],
      "metadata": {
        "id": "5lx5bcr1P14y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in filtered_tokens]\n",
        "print(\"--- Step 3: Stemming (Porter Stemmer) ---\")\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYe0d6IxNBkb",
        "outputId": "e1c1144f-1c3b-4d64-f78f-03912ceec433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 3: Stemming (Porter Stemmer) ---\n",
            "['natur', 'languag', 'process', 'fascin', 'field', 'help', 'comput', 'understand', 'interpret', 'gener', 'human', 'languag', 'perform', 'entir', 'pipelin', 'transform', 'text']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Lemmatization (WordNet Lemmatizer)"
      ],
      "metadata": {
        "id": "4I_G5nj2P6Pg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "print(\"--- Step 4: Lemmatization (WordNet Lemmatizer) ---\")\n",
        "print(lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbzfp95oNCBL",
        "outputId": "8202dbd2-443e-43e5-8e3f-2cacc1bc8891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 4: Lemmatization (WordNet Lemmatizer) ---\n",
            "['natural', 'language', 'processing', 'fascinating', 'field', 'help', 'computer', 'understand', 'interpret', 'generate', 'human', 'language', 'performing', 'entire', 'pipeline', 'transform', 'text']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2: Define NLP and its Real-Time Application\n",
        "\n",
        "### What is NLP?\n",
        "\n",
        "Natural Language Processing (NLP) is a subfield of artificial intelligence (AI) that gives computers the ability to understand, interpret, and generate human language in a valuable way. It combines computational linguistics (rule-based modeling of human language) with statistical, machine learning, and deep learning models. The goal is to bridge the gap between human communication and computer understanding.\n",
        "\n",
        "### Real-Time Application in a Specific Domain\n",
        "\n",
        "| Domain | Application | Description |\n",
        "| :--- | :--- | :--- |\n",
        "| **Customer Service** | **Real-Time Chatbots** | In e-commerce or telecommunications, chatbots use NLP to **instantly** understand a customer's query (intent recognition) from their typed or spoken language and provide relevant, real-time responses or route the user to the correct human agent. |\n",
        "| **Finance/Trading** | **Sentiment Analysis on News Feeds** | Algorithms analyze high-volume, real-time news articles, social media posts, and company reports to gauge the market's **sentiment** (positive, negative, or neutral) towards a stock or commodity. This helps inform automated, high-frequency trading decisions. |\n",
        "| **Healthcare** | **Clinical Decision Support** | NLP is used in real-time to process a doctor's transcribed notes or electronic health records (EHRs), **extracting key information** like diagnoses, medications, and allergies, and providing instant, relevant alerts or suggestions to the clinician. |"
      ],
      "metadata": {
        "id": "o6h1X3BuNMIO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3: What is NLU and NLG?\n",
        "\n",
        "### **NLU** and **NLG** are two major components of the overall NLP field.\n",
        "\n",
        "| Component | Full Name | Definition | Analogy |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **NLU** | **Natural Language Understanding** | The process of getting computers to **comprehend the meaning** of human language input. This involves tasks like determining the underlying *intent*, *sentiment*, and *context* of the text, not just the individual words. | A student **reading and understanding** a complex textbook chapter. |\n",
        "| **NLG** | **Natural Language Generation** | The process of getting computers to **produce coherent and human-like text** or speech as output. It involves planning what to say, structuring the sentences, and selecting the appropriate words. | A student **writing a well-structured essay** based on the information they learned. |"
      ],
      "metadata": {
        "id": "oWvnsmkbOGhY"
      }
    }
  ]
}